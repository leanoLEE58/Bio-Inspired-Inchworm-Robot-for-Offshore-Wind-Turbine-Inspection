# ğŸŒŠ Bio-Inspired Inchworm Robot for Offshore Wind Turbine Inspection

<div align="center">

[![Project Status](https://img.shields.io/badge/Status-Prototype%20Testing-yellow)](https://github.com/leanoLEE58/Bio-Inspired-Inchworm-Robot-for-Offshore-Wind-Turbine-Inspection)
[![University](https://img.shields.io/badge/University-Ocean%20University%20of%20China-blue)](http://www.ouc.edu.cn/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Funding](https://img.shields.io/badge/Funding-National%20Innovation%20Program-orange)](https://github.com/leanoLEE58/Bio-Inspired-Inchworm-Robot-for-Offshore-Wind-Turbine-Inspection)

**A rigid-flexible coupled robotic system with vision-tactile fusion for autonomous inspection of confined spaces in offshore wind turbines**

[ğŸ“º Demo Video](#-demonstration-videos) | [ğŸ”§ Hardware](#-hardware-design) | [ğŸ’» Software](#-software-implementation) | [ğŸ“Š Results](#-experimental-results)

---

### ğŸ¬ System Overview

<!-- æ›¿æ¢ä¸ºä½ ä¸Šä¼ çš„è§†é¢‘æˆªå›¾ï¼Œç‚¹å‡»å¯è·³è½¬è§†é¢‘ -->
![System Overview](https://github.com/user-attachments/assets/your-overview-image-id.png)

*Click image above to watch full demonstration video*

</div>

---

## ğŸ“– Project Introduction

This project presents a **bio-inspired inchworm robot** designed for autonomous inspection of offshore wind turbine internal structures. The system addresses three critical challenges in wind turbine maintenance:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Challenge 1: "Cannot Enter" â”‚
â”‚ â€¢ 30%+ unreachable areas due to confined spaces (Ã˜ < 40cm) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Challenge 2: "Cannot Detect Accurately" â”‚
â”‚ â€¢ 40% defect miss rate in low-light environments (â‰¤100 lux) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Challenge 3: "Cannot Touch Safely" â”‚
â”‚ â€¢ Rigid robots damage fragile components (>50N contact force) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

text


**Our Solution:**
- ğŸ› **Inchworm Locomotion**: Bio-inspired "attach-extend-release" gait for Ã˜ â‰¥ 25cm confined spaces
- ğŸ‘ï¸ **Vision-Tactile Fusion**: YOLOv7 vision + 9DTact tactile sensors for robust defect detection
- ğŸ¦¾ **Rigid-Flexible Coupling**: Adjustable stiffness (0.1-50 NÂ·m/rad) pneumatic manipulator

---

## âœ¨ Key Features

### Quick Performance Overview

| Metric | Specification |
|--------|--------------|
| **Minimum Passage** | Ã˜ 25cm (design) / Ã˜ 30cm (current) |
| **Positioning Accuracy** | Â±0.5mm (target) / Â±1.2mm (achieved) |
| **Contact Force** | â‰¤5N (safe for fragile materials) |
| **Suction Force** | â‰¥20N per vacuum cup |
| **Vision Detection** | 0.1mm crack resolution @ >100 lux |
| **Tactile Resolution** | 0.01N @ 1kHz sampling rate |

---

## ğŸ¥ Demonstration Videos

### Full System Demonstration

<!-- ä¸Šä¼ åæ›¿æ¢ä¸ºå®é™…çš„è§†é¢‘é¢„è§ˆå›¾å’Œé“¾æ¥ -->
![Full Demo](https://github.com/user-attachments/assets/your-full-demo-thumbnail.png)

*3-minute comprehensive system overview (Upload your video and link here)*

---

### Inchworm Locomotion in Action

<!-- GIF ç¤ºä¾‹ - ä¸Šä¼ åæ›¿æ¢ -->
![Inchworm Motion](https://github.com/user-attachments/assets/your-inchworm-motion.gif)

*Bio-inspired gait cycle: Attach â†’ Extend â†’ Release*

---

### Vision-Tactile Detection Demo

<table>
<tr>
<td width="50%">

![Vision Detection](https://github.com/user-attachments/assets/your-vision-detection.gif)

*YOLOv7 real-time crack detection*

</td>
<td width="50%">

![Tactile Sensing](https://github.com/user-attachments/assets/your-tactile-heatmap.gif)

*Tactile pressure mapping & 3D reconstruction*

</td>
</tr>
</table>

---

## ğŸ—ï¸ System Architecture

### Overall System Diagram
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Control Terminal â”‚
â”‚ Xbox Controller / Upper Computer GUI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Bluetooth / WiFi
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Control Unit (ESP32) â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â€¢ Locomotion Control (Inchworm Gait FSM) â”‚ â”‚
â”‚ â”‚ â€¢ PWM â†’ Voltage â†’ Pressure Mapping â”‚ â”‚
â”‚ â”‚ â€¢ PID Closed-Loop Control â”‚ â”‚
â”‚ â”‚ â€¢ Multi-Modal Data Fusion (Vision + Tactile) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ â”‚ â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ OAK-D â”‚ â”‚ 9DTact â”‚ â”‚ Pneumatic â”‚ â”‚ Vacuum â”‚
â”‚ Camera â”‚ â”‚ Sensor â”‚ â”‚ Valves â”‚ â”‚ Pump â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ 6Ã— PAM â”‚
â”‚ Actuators â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

text


### Modular Robot Structure

![Modular Structure](https://github.com/user-attachments/assets/your-modular-structure.png)

*Three-segment design: Front Anchor â†’ Drive Section â†’ Rear Anchor â†’ End-Effector*

---

## ğŸ”§ Hardware Design

### Core Components

| Category | Component | Model/Spec | Quantity |
|----------|-----------|-----------|----------|
| **Main Control** | Microcontroller | ESP32-DevKitC | 1 |
| **Vision** | Camera | OAK-D-Lite (4MP) | 1 |
| **Tactile** | Sensor | Custom 9DTact | 1 |
| **Actuation** | Proportional Valve | SMC ITV0010 | 3 |
| | Vacuum Pump | ZH10DSA-06-06-08 | 1 |
| | Servo Motor | MG996R (20kgÂ·cm) | 2 |
| **Power** | Battery | Li-ion 7.4V 5000mAh | 1 |

### Prototype Photos

<table>
<tr>
<td><img src="https://github.com/user-attachments/assets/your-pam-muscles.jpg" width="250"><br><i>6Ã— PAM Actuators</i></td>
<td><img src="https://github.com/user-attachments/assets/your-vacuum-system.jpg" width="250"><br><i>Vacuum Suction System</i></td>
<td><img src="https://github.com/user-attachments/assets/your-esp32-board.jpg" width="250"><br><i>ESP32 Control Board</i></td>
</tr>
<tr>
<td><img src="https://github.com/user-attachments/assets/your-flexible-gripper.jpg" width="250"><br><i>TPU Flexible Gripper</i></td>
<td><img src="https://github.com/user-attachments/assets/your-9dtact-sensor.jpg" width="250"><br><i>9DTact Tactile Sensor</i></td>
<td><img src="https://github.com/user-attachments/assets/your-full-assembly.jpg" width="250"><br><i>Full Assembly</i></td>
</tr>
</table>

---

## ğŸ’» Software Implementation

### Control System Highlights

#### PWM-Pressure Calibration

![PWM Mapping](https://github.com/user-attachments/assets/your-pwm-calibration.png)

*Experimental calibration: PWM â†’ Voltage â†’ Pressure â†’ PAM Length*

#### Inchworm Gait Control (Core Algorithm)

```cpp
// Simplified locomotion control
void inchwormGait(float stepSize_cm) {
    // Phase 1: Front anchor attachment
    frontVacuum.attach(-50);  // -50 kPa
    delay(500);
    
    // Phase 2: PAM extension
    for(int i = 0; i < 6; i++) {
        pam[i].setPressure(0.3);  // 0.3 MPa
    }
    
    // Phase 3: Rear release & contraction
    rearVacuum.release();
    for(int i = 0; i < 6; i++) {
        pam[i].setPressure(0.5);  // Max contraction
    }
    
    // Phase 4: Rear reattach & front release
    rearVacuum.attach(-50);
    frontVacuum.release();
}
Vision Processing Pipeline
YOLOv7 Crack Detection
Python

class CrackDetector:
    def detect(self, image):
        # Preprocessing
        img_tensor = self.preprocess(image)
        
        # Inference (on-board MyriadX chip)
        with torch.no_grad():
            pred = self.model(img_tensor)[0]
        
        # Post-processing
        detections = non_max_suppression(pred, conf_thres=0.5)
        
        # Extract crack features
        results = []
        for det in detections:
            crack_length_mm = self.calculate_size(det['bbox'])
            results.append({
                'bbox': det['bbox'],
                'confidence': det['conf'],
                'length_mm': crack_length_mm
            })
        
        return results
Detection Results
<table> <tr> <td width="50%">
Crack Detection 1

Surface crack detection (0.5mm width)

</td> <td width="50%">
Crack Detection 2

Multiple defect detection

</td> </tr> </table>
ğŸ“Š Experimental Results
Performance Metrics Summary
Metric	Target	Achieved	Status
Min. Passage Diameter	Ã˜ 25cm	Ã˜ 30cm	ğŸ”§ In Progress
Positioning Accuracy	Â±0.5mm	Â±1.2mm	ğŸ”§ PID Tuning
Contact Force	â‰¤5N	â‰¤8N	ğŸ”§ Refinement
Suction Force	â‰¥20N	22N âœ…	âœ… Met
Vision Detection (>100 lux)	90%	85%	âš ï¸ Dataset Expansion
Tactile Resolution	0.01N	0.015N	âš ï¸ Acceptable
Detection Accuracy by Environment
Lighting (lux)	Vision Only	Tactile Only	Fused (Ours)
>500	92%	78%	95% âœ…
100-500	85%	82%	92% âœ…
50-100	65%	85%	88% âœ…
<50	35%	87%	85% âœ…
Kinematic Model Validation
Simulation vs Real

MATLAB simulation vs. experimental bending angles (avg. error: 8.2mm)

ğŸš€ Installation & Usage
Quick Start
1. Clone Repository
Bash

git clone https://github.com/leanoLEE58/Bio-Inspired-Inchworm-Robot-for-Offshore-Wind-Turbine-Inspection.git
cd Bio-Inspired-Inchworm-Robot-for-Offshore-Wind-Turbine-Inspection
2. Install Dependencies
Bash

# Python dependencies
pip install -r requirements.txt

# Arduino libraries (for ESP32)
arduino-cli lib install "ESP32Servo" "AsyncTCP" "ESPAsyncWebServer"
3. Flash ESP32 Firmware
Bash

cd firmware/esp32_controller
pio run --target upload
4. Run GUI
Bash

python gui/main_interface.py
Basic Operation
Python

from robot_controller import InchwormRobot

# Initialize robot
robot = InchwormRobot(port='/dev/ttyUSB0')
robot.connect()
robot.calibrate()

# Manual control
robot.set_mode('manual')
robot.move_forward(distance=10)  # Move 10cm

# Start inspection
robot.start_inspection(duration=60)  # Scan for 60 seconds
results = robot.get_latest_detections()

# Export report
robot.export_report('inspection_2025_01_20.json')
ğŸ“‚ Repository Structure
text

Bio-Inspired-Inchworm-Robot/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”‚
â”œâ”€â”€ docs/                              # Documentation & media
â”‚   â”œâ”€â”€ images/                        # Photos & diagrams
â”‚   â”œâ”€â”€ videos/                        # Demo videos
â”‚   â””â”€â”€ assembly_guide.pdf             # Hardware assembly
â”‚
â”œâ”€â”€ firmware/                          # ESP32 embedded code
â”‚   â””â”€â”€ esp32_controller/
â”‚       â”œâ”€â”€ main.ino
â”‚       â”œâ”€â”€ locomotion_control.cpp
â”‚       â””â”€â”€ pid_controller.cpp
â”‚
â”œâ”€â”€ vision_module/                     # Computer vision
â”‚   â”œâ”€â”€ crack_detector.py
â”‚   â”œâ”€â”€ image_enhancement.py
â”‚   â”œâ”€â”€ tactile_processor.py
â”‚   â””â”€â”€ weights/
â”‚       â””â”€â”€ yolov7-crack.pt
â”‚
â”œâ”€â”€ gui/                               # User interface
â”‚   â”œâ”€â”€ main_interface.py
â”‚   â””â”€â”€ widgets/
â”‚
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ calibrate_pressure.py
â”‚   â””â”€â”€ test_pam_linearity.py
â”‚
â”œâ”€â”€ config/                            # Configuration
â”‚   â””â”€â”€ robot_params.yaml
â”‚
â””â”€â”€ mechanical/                        # CAD files
    â”œâ”€â”€ cad/                           # SolidWorks
    â””â”€â”€ stl/                           # 3D printable
ğŸ”® Future Work
Next Steps (6 Months)
 Reduce positioning error to Â±0.5mm (optical encoder feedback)
 Expand YOLOv7 training dataset to 3,000+ images
 Implement ROS2 integration for modular control
 Field testing in simulated wind turbine environment
Long-Term Vision (1-2 Years)
 SLAM-based autonomous navigation
 Multi-robot collaborative inspection
 Underwater adaptation for offshore subsea structures
 Commercial prototype development
ğŸ‘¥ Team
Core Contributors
<table> <tr> <td align="center" width="20%"> <b>Tian Xinrong<br>(Li Jiayi)</b><br> <i>Project Leader</i><br> Control & Vision<br> ğŸ“§ <a href="mailto:332323223@stu.ouc.edu.cn">Email</a> </td> <td align="center" width="20%"> <b>Lu Jingjing</b><br> <i>Co-Developer</i><br> Algorithms & Circuits </td> <td align="center" width="20%"> <b>Zhang Siyuan</b><br> <i>Mechanical Engineer</i><br> CAD & Fabrication </td> <td align="center" width="20%"> <b>Lu Guohang</b><br> <i>Sensor Specialist</i><br> Tactile & PCB </td> <td align="center" width="20%"> <b>Zheng Zhiyang</b><br> <i>Fabrication Lead</i><br> 3D Printing </td> </tr> </table>
Faculty Advisors
Prof. Chen Qi (é™ˆçª) - College of Engineering, Ocean University of China
Dr. Zhu Jinchi (æœ±è¿‘èµ¤) - Experimental Engineer, OUC
ğŸ™ Acknowledgments
Funding
This project is supported by:

Ocean University of China - National Innovation Training Program (Â¥30,500)
National Natural Science Foundation of China - Grant No. 42204005
Shandong Provincial Natural Science Foundation - Grant No. ZR2022QF130
Open Source References
YOLOv7 - Object detection framework
OpenCV - Computer vision library
ESP32 Arduino Core - Embedded development
ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

Note: Patent pending (CN202410XXXXX.X). For commercial use, please contact the team.

ğŸ“ Contact
Project Lead: Tian Xinrong (Li Jiayi)
Email: 332323223@stu.ouc.edu.cn
Institution: Ocean University of China
GitHub: @leanoLEE58

For technical questions or collaboration, please open an issue or contact us directly.

ğŸ“š Citation
If you use this work in your research, please cite:

bibtex

@misc{tian2025inchworm,
  title={Bio-Inspired Inchworm Robot for Offshore Wind Turbine Inspection},
  author={Tian, Xinrong and Lu, Jingjing and Zhang, Siyuan and Lu, Guohang and Zheng, Zhiyang},
  year={2025},
  institution={Ocean University of China},
  url={https://github.com/leanoLEE58/Bio-Inspired-Inchworm-Robot-for-Offshore-Wind-Turbine-Inspection}
}
<div align="center">
â­ Star this repository if you find it interesting! â­
Contributions, issues, and feature requests are welcome!

Made with â¤ï¸ by the Inchworm Robot Team @ Ocean University of China

ğŸ” Back to Top

</div> ```
